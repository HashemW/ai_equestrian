{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71eff5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "video 1/1 (frame 1/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 16.2ms\n",
      "video 1/1 (frame 2/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 21.2ms\n",
      "video 1/1 (frame 3/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.8ms\n",
      "video 1/1 (frame 4/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 16.3ms\n",
      "video 1/1 (frame 5/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 15.7ms\n",
      "video 1/1 (frame 6/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 17.4ms\n",
      "video 1/1 (frame 7/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 17.4ms\n",
      "video 1/1 (frame 8/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.6ms\n",
      "video 1/1 (frame 9/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 15.9ms\n",
      "video 1/1 (frame 10/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 19.0ms\n",
      "video 1/1 (frame 11/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 33.9ms\n",
      "video 1/1 (frame 12/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.4ms\n",
      "video 1/1 (frame 13/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 18.3ms\n",
      "video 1/1 (frame 14/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 22.9ms\n",
      "video 1/1 (frame 15/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 18.6ms\n",
      "video 1/1 (frame 16/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 14.7ms\n",
      "video 1/1 (frame 17/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 18.8ms\n",
      "video 1/1 (frame 18/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 19.1ms\n",
      "video 1/1 (frame 19/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 25.4ms\n",
      "video 1/1 (frame 20/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.7ms\n",
      "video 1/1 (frame 21/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 15.4ms\n",
      "video 1/1 (frame 22/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 17.1ms\n",
      "video 1/1 (frame 23/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 21.9ms\n",
      "video 1/1 (frame 24/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 20.1ms\n",
      "video 1/1 (frame 25/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 34.6ms\n",
      "video 1/1 (frame 26/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 23.7ms\n",
      "video 1/1 (frame 27/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 14.7ms\n",
      "video 1/1 (frame 28/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 22.0ms\n",
      "video 1/1 (frame 29/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 21.2ms\n",
      "video 1/1 (frame 30/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 17.1ms\n",
      "video 1/1 (frame 31/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.9ms\n",
      "video 1/1 (frame 32/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 14.9ms\n",
      "video 1/1 (frame 33/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 21.0ms\n",
      "video 1/1 (frame 34/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 24.6ms\n",
      "video 1/1 (frame 35/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 14.5ms\n",
      "video 1/1 (frame 36/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 14.7ms\n",
      "video 1/1 (frame 37/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 18.6ms\n",
      "video 1/1 (frame 38/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 14.1ms\n",
      "video 1/1 (frame 39/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 16.7ms\n",
      "video 1/1 (frame 40/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 17.9ms\n",
      "video 1/1 (frame 41/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 14.5ms\n",
      "video 1/1 (frame 42/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 16.8ms\n",
      "video 1/1 (frame 43/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 15.1ms\n",
      "video 1/1 (frame 44/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 16.6ms\n",
      "video 1/1 (frame 45/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 17.2ms\n",
      "video 1/1 (frame 46/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.9ms\n",
      "video 1/1 (frame 47/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.1ms\n",
      "video 1/1 (frame 48/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 15.4ms\n",
      "video 1/1 (frame 49/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.0ms\n",
      "video 1/1 (frame 50/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 15.9ms\n",
      "video 1/1 (frame 51/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 26.2ms\n",
      "video 1/1 (frame 52/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 17.9ms\n",
      "video 1/1 (frame 53/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 16.6ms\n",
      "video 1/1 (frame 54/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.4ms\n",
      "video 1/1 (frame 55/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 14.2ms\n",
      "video 1/1 (frame 56/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 16.2ms\n",
      "video 1/1 (frame 57/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.3ms\n",
      "video 1/1 (frame 58/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 15.3ms\n",
      "video 1/1 (frame 59/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.4ms\n",
      "video 1/1 (frame 60/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 17.6ms\n",
      "video 1/1 (frame 61/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 12.6ms\n",
      "video 1/1 (frame 62/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 28.6ms\n",
      "video 1/1 (frame 63/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.2ms\n",
      "video 1/1 (frame 64/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 15.2ms\n",
      "video 1/1 (frame 65/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.4ms\n",
      "video 1/1 (frame 66/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 15.8ms\n",
      "video 1/1 (frame 67/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 14.4ms\n",
      "video 1/1 (frame 68/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 17.8ms\n",
      "video 1/1 (frame 69/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 17.9ms\n",
      "video 1/1 (frame 70/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 15.3ms\n",
      "video 1/1 (frame 71/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 14.4ms\n",
      "video 1/1 (frame 72/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 16.9ms\n",
      "video 1/1 (frame 73/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 17.1ms\n",
      "video 1/1 (frame 74/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.2ms\n",
      "video 1/1 (frame 75/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 15.4ms\n",
      "video 1/1 (frame 76/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 24.7ms\n",
      "video 1/1 (frame 77/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 23.5ms\n",
      "video 1/1 (frame 78/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 16.7ms\n",
      "video 1/1 (frame 79/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.8ms\n",
      "video 1/1 (frame 80/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 22.8ms\n",
      "video 1/1 (frame 81/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 18.4ms\n",
      "video 1/1 (frame 82/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 13.4ms\n",
      "video 1/1 (frame 83/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 18.4ms\n",
      "video 1/1 (frame 84/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 15.7ms\n",
      "video 1/1 (frame 85/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 14.2ms\n",
      "video 1/1 (frame 86/86) /home/hashemw/ai_equestrian/riding1.mp4: 384x640 1 person, 15.4ms\n",
      "Speed: 2.9ms preprocess, 17.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/pose/track5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The keypoints are stored like so:\n",
    "# 1. Nose\n",
    "# 2. Left Eye\n",
    "# 3. Right Eye\n",
    "# 4. Left Ear\n",
    "# 5. Right Ear\n",
    "# 6. Left Shoulder\n",
    "# 7. Right Shoulder\n",
    "# 8. Left Elbow\n",
    "# 9. Right Elbow\n",
    "# 10. Left Wrist\n",
    "# 11. Right Wrist\n",
    "# 12. Left Hip\n",
    "# 13. Right Hip\n",
    "# 14. Left Knee\n",
    "# 15. Right Knee\n",
    "# 16. Left Ankle\n",
    "# 17. Right Ankle\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "#get yolo from ultralytics\n",
    "model = YOLO(\"yolo11n-pose.pt\")\n",
    "#open video file using opencv\n",
    "cap = cv2.VideoCapture(\"riding1.mp4\")\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Set up a video writer with same size & fps as input\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # You can also try 'XVID'\n",
    "out = cv2.VideoWriter(\"output_overlay.mp4\", fourcc, fps, (width, height))\n",
    "#while True:\n",
    "#start the tracker in STREAM MODE!!!! This yields results frame by frame\n",
    "results = model.track(source=\"riding1.mp4\", tracker=\"bytetrack.yaml\", persist=True, stream=True, save=True)\n",
    "#loop through each frame\n",
    "def angle_between(p1, p2, p3):\n",
    "    \"\"\"Returns the angle (in degrees) at p2 formed by points p1-p2-p3\"\"\"\n",
    "    a = np.array(p1) - np.array(p2)\n",
    "    b = np.array(p3) - np.array(p2)\n",
    "    cosine_angle = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    angle = np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))\n",
    "    return angle\n",
    "for result in results:\n",
    "    #make a copy of the original image from the vid\n",
    "    frame = result.orig_img.copy()\n",
    "\n",
    "    # check if keypoints exist in the current frame\n",
    "    if result.keypoints is not None:\n",
    "        #go through each detected person\n",
    "        for keypoint_set in result.keypoints.xy:\n",
    "            keypoints_np = keypoint_set.cpu().numpy()\n",
    "            Nose = keypoints_np[0]\n",
    "            left_eye = keypoints_np[1]\n",
    "            right_eye = keypoints_np[2]\n",
    "            left_ear = keypoints_np[3]\n",
    "            right_ear = keypoints_np[4]\n",
    "            left_shoulder = keypoints_np[5]\n",
    "            right_shoulder = keypoints_np[6]\n",
    "            left_elbow = keypoints_np[7]\n",
    "            right_elbow = keypoints_np[8]\n",
    "            left_wrist = keypoints_np[9]\n",
    "            right_wrist = keypoints_np[10]\n",
    "            left_hip = keypoints_np[11]\n",
    "            right_hip = keypoints_np[12]\n",
    "            left_knee = keypoints_np[13]\n",
    "            right_knee = keypoints_np[14]\n",
    "            left_ankle = keypoints_np[15]\n",
    "            right_ankle = keypoints_np[16]\n",
    "            #draw a circle on each keypoint, showing the joints! (SO COOL!)\n",
    "            for x, y in keypoint_set:\n",
    "                cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 0), -1)\n",
    "            # we are going to check three positions.\n",
    "            #1. shoulder to elbow to wrist (125-155 degree angle)\n",
    "            leftAngle = angle_between(left_shoulder, left_elbow, left_wrist)\n",
    "            if leftAngle > 125 and leftAngle < 155:\n",
    "                cv2.putText(frame, \"Good \" + str(leftAngle), (int(left_elbow[0]), int(left_elbow[1])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Bad \" + str(leftAngle), (int(left_elbow[0]), int(left_elbow[1])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 2)\n",
    "            #2. Hip to knee to ankle (80-125 degree angle)\n",
    "            leftKneeAngle = angle_between(left_hip, left_knee, left_ankle)\n",
    "            if leftKneeAngle > 80 and leftKneeAngle < 125:\n",
    "                cv2.putText(frame, \"Good \" + str(leftKneeAngle), (int(left_hip[0]), int(left_hip[1])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Bad \" + str(leftKneeAngle), (int(left_hip[0]), int(left_hip[1])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 2)\n",
    "            #3. shoulder to hip to knee (130-145 degree angle)\n",
    "            leftShoulderAngle = angle_between(left_shoulder, left_hip, left_knee)\n",
    "            if leftShoulderAngle > 115 and leftShoulderAngle < 140:\n",
    "                cv2.putText(frame, \"Good \" + str(leftShoulderAngle), (int(left_shoulder[0]), int(left_shoulder[1])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Bad \" + str(leftShoulderAngle), (int(left_shoulder[0]), int(left_shoulder[1])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 2)\n",
    "            out.write(frame)\n",
    "            \n",
    "\n",
    "    # show frame\n",
    "    cv2.imshow(\"Custom Pose Overlay\", frame)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# Release the video writer\n",
    "out.release()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
